{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feather as ft\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from math import log, e\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import useful functions\"\"\"\n",
    "from entropy_functions import shannon_entropy, entropy, cross_entropy,LZ_entropy\n",
    "\n",
    "\"\"\" Compute predictability given the lengths of sequences and the LZ-entropy\"\"\"\n",
    "import mpmath\n",
    "\n",
    "# As required by algorithm, N should be large, we set e as the threshold of N. \n",
    "# if it is smaller than threshold, we will just print NA\n",
    "def getPredictability(N, S, e=100):\n",
    "    if N >= e:\n",
    "        f = lambda x: (((1-x)/(N-1)) **(1-x))* x**x - 2**(-S)\n",
    "        root = mpmath.findroot(f, 1)\n",
    "        return float(root.real)\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Mobility dataset import\"\"\"\n",
    "df_wp = ft.read_dataframe('data/weeplace_checkins_without_loc_NA.feather') # it is the dataset without NA location\n",
    "\n",
    "# # it will be the same if you use the original csv file.\n",
    "# df_wp= pd.read_csv('data/weeplace_checkins.csv')  # this is original Weeplace dataset without any processing, including some NA location\n",
    "# df_wp = df_wp.dropna(subset=[\"placeid\",'userid', 'datetime'])\n",
    "\n",
    "\"\"\"Previous results of meetup information import\"\"\"\n",
    "pickle_in = open(\"meetup_store.pickle\", \"rb\")\n",
    "meetup_store = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = list(set(df_wp['userid'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read picle file\n",
    "pickle_in = open(\"user_placeidT.pickle\", \"rb\")\n",
    "user_placeidT = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\"\"\" meetup class define \"\"\"\n",
    "\n",
    "\"\"\" import useful functions\"\"\"\n",
    "from entropy_functions import shannon_entropy, entropy, cross_entropy,LZ_entropy\n",
    "\n",
    "\"\"\" Compute predictability given the lengths of sequences and the LZ-entropy\"\"\"\n",
    "import mpmath\n",
    "import numpy as np\n",
    "\n",
    "# As required by algorithm, N should be large, we set e as the threshold of N. \n",
    "# if it is smaller than threshold, we will just print NA\n",
    "def getPredictability(N, S, e=100):\n",
    "    if N >= e:\n",
    "        f = lambda x: (((1-x)/(N-1)) **(1-x))* x**x - 2**(-S)\n",
    "        root = mpmath.findroot(f, 1)\n",
    "        return float(root.real)\n",
    "    else: \n",
    "        return np.nan\n",
    "\n",
    "class MeetupStrategy():\n",
    "    \n",
    "    def __init__(self, userlist, user_meetup, placeidT, epsilon=2):\n",
    "        # MeetupStrategy needs to have three important inputs, userlist, user_meetup and placeidT.\n",
    "        # It can be replaced as dataset, but it will cost more time any time call the calss\n",
    "        self.userlist = userlist \n",
    "        self.user_meetup = user_meetup\n",
    "        self.placeidT = placeidT\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        \n",
    "    def extract_info(self, user):\n",
    "        # extract temporal-spatial information for each user\n",
    "        user_temporal_placeid = self.placeidT[user]\n",
    "        user_time = pd.to_datetime(user_temporal_placeid.index).tolist()\n",
    "        user_placeid = user_temporal_placeid['placeid'].tolist()\n",
    "        N_uniq_placeid = len(set(user_placeid))\n",
    "        N_placeid = len(user_placeid)\n",
    "        \n",
    "        return user_time, N_uniq_placeid, N_placeid, user_placeid\n",
    "    \n",
    "    \n",
    "    def cross_entropy_pair(self, length_ego, alters_L, ave_length):\n",
    "        # length_ego: the length of the visited placedid sequence.\n",
    "        # alters_L: cross-parsed match legnths for the alters given\n",
    "        # ave_length: the weighted average lengths of all the users in B\n",
    "        alters_Lmax = np.amax(alters_L, axis=0)\n",
    "        return (1.0*length_ego/sum(alters_Lmax)) * np.log2(ave_length)\n",
    "    \n",
    "\n",
    "    def weight(self, ego_L, alter_L=None):\n",
    "        if alter_L is None:\n",
    "            return len(ego_L)\n",
    "        else:\n",
    "            # count how many elements of ego_L is in alter_L\n",
    "            return sum(x in alter_L for x in ego_L)\n",
    "    \n",
    "    \n",
    "    def cross_entropy_element(self, ego_time, ego_placeid, ego_L, alter, alters, L, length_alters):\n",
    "        length_ego = len(ego_placeid)\n",
    "        alterid = alters.index(alter)\n",
    "        \n",
    "        # included rank is j+1\n",
    "        rank = alterid + 1\n",
    "        \n",
    "        ego_time, length_ego_uni, length_ego, ego_placeid = self.extract_info(ego)\n",
    "        alter_time, ~ , ~, alter_placeid = self.extract_info(alter)\n",
    "        \n",
    "        \"\"\"Be careful: W1 in cross_entropy is B in the paper, W2 is cross_entropy is A in the paper \"\"\"        \n",
    "        # so we need to get the relative time order of ego in alter (abosulte position of ego+alter)\n",
    "        # for function cross_entropy, we need to have PTs        \n",
    "        total_time = sorted(ego_time + alter_time)\n",
    "        PTs = [total_time.index(x) for x in ego_time]\n",
    "        \n",
    "        \"\"\" function cross_entropy can return L, as defintion of cumulative cross entropy, we need to get max \"\"\"\n",
    "        \n",
    "        # compute cross entropy with only this alter\n",
    "        \"\"\" For alter\"\"\"\n",
    "        CE_alter = cross_entropy(alter_placeid,ego_placeid, PTs)\n",
    "        Pi_alter = getPredictability(length_ego, CE_alter, e=self.epsilon)\n",
    "        \n",
    "        \"\"\" For alters \"\"\"\n",
    "        # obtain the cross-parsed match length\n",
    "        L[alterid] = cross_entropy(alter_placeid,ego_placeid, PTs, lambdas=True)\n",
    "        # TODO: define weight \n",
    "        wb[alterid] = weight(ego_L, alter)       \n",
    "        \n",
    "        # for alters: top above all alters\n",
    "        alters_L = L[:alterid+1]\n",
    "        alters_length = length_alters[:alteridr+1]\n",
    "        \n",
    "        # average lengths\n",
    "        ave_length = np.array(alters_length) * np.array(wb) / sum(wb)\n",
    "        \n",
    "        # CCE for all above alters\n",
    "        CCE_alters = self.cross_entropy_pair(length_ego, alters_L, ave_length)\n",
    "        Pi_alters = getPredictability(length_ego, CCE_alters, e=self.epsilon)\n",
    "        \n",
    "        \"\"\"For only this alter + ego\"\"\"\n",
    "        # for only this alter and ego\n",
    "        ego_alter_L = [ego_L, L[alterid]]\n",
    "        bi_length = np.array([length_alters[alterid], length_ego])\n",
    "        # TODO: weight \n",
    "        bi_weight = np.array([weight[alterid], weight(ego)])\n",
    "        ave_length = np.mean(bi_length * bi_weight / sum(bi_weight))\n",
    "        CCE_ego_alter = self.cross_entropy_pair(length_ego, ego_alter_L, ave_length)\n",
    "        Pi_ego_alter = getPredictability(length_ego, CCE_ego_alter, e=self.epsilon)\n",
    "        \n",
    "        \"\"\"For all above alters + ego\"\"\"\n",
    "        # for ego+alters: top above all alters + ego\n",
    "        alters_L.append(ego_L)\n",
    "        alters_length.append(length_ego)\n",
    "        # TODO: weight\n",
    "        ego_alters_weight = weight[:alterid+1] + [weight(ego)]\n",
    "        ave_length = np.mean(np.array(alters_length) * np.array(ego_alters_weight) / sum(ego_alters_weight))\n",
    "        CCE_ego_atlers = self.cross_entropy_pair(length_ego, alters_L, ave_length)\n",
    "        Pi_ego_alters = getPredictability(length_ego, CCE_ego_alters, e=self.epsilon)\n",
    "        \n",
    "        return [alter, rank, wb[alterid], \n",
    "                CE_alter, CCE_alters, CCE_ego_alter, CCE_ego_atlers,\n",
    "                Pi_alter, Pi_alters, Pi_ego_alter, Pi_ego_atlers,\n",
    "               ]\n",
    "\n",
    "    def ego_meetup(self, ego, tempsave=False):\n",
    "        # extraact information of ego\n",
    "        ego_time, length_ego_uni, length_ego, ego_placeid = self.extract_info(ego)\n",
    "        \n",
    "        # compute the cumulative cross entropy for an ego\n",
    "        alters = self.user_meetup[self.user_meetup['userid_x']==ego]['userid_y'].tolist()\n",
    "        df_ego_meetup = self.user_meetup[self.user_meetup['userid_x']==ego]\n",
    "        \n",
    "        ego_LZ_entropy = LZ_entropy(ego_placeid, e=self.epsilon) \n",
    "        ego_L = LZ_entropy(ego_placeid, e=self.epsilon, lambdas=True)\n",
    "        \n",
    "        ego_info = [self.cross_entropy_element(ego_time, ego_placeid, ego_L, alter, alters, \\\n",
    "                                               L, length_alters) for alter in alters]\n",
    "        ego_info = pd.DataFrame(ego_info, columns=[\n",
    "            'userid_y', 'Included Rank', 'Weight', \n",
    "            'CE_alter', 'CCE_alters', 'CCE_ego_alter', 'CCE_ego_atlers',\n",
    "            'Pi_alter', 'Pi_alters', 'Pi_ego_alter', 'Pi_ego_atlers',\n",
    "        ])\n",
    "        \n",
    "        # combine two parts of meetup information\n",
    "        ego_meetup = pd.merge(df_ego_meetup, ego_info, on='userid_y')\n",
    "        \n",
    "        if tempsave:\n",
    "            ego_meetup.to_csv('user-meetup-part.csv', index=False, mode='a', header=False)    \n",
    "\n",
    "        return ego_meetup\n",
    "        \n",
    "    def user_info(self, start=0, end=len(self.userlist)):\n",
    "        meetup_list = [ego_meetup(ego) for ego in userlist[start:end]]\n",
    "        user_meetup = pd.concat(meetup_list)\n",
    "        \n",
    "        # save the file \n",
    "        user_meetup.to_csv('user-meetup-full', index=False)\n",
    "        \n",
    "        return user_meetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return [x, x*x, x*x*x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [func(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(a, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b    c\n",
       "0  0   0    0\n",
       "1  1   1    1\n",
       "2  2   4    8\n",
       "3  3   9   27\n",
       "4  4  16   64\n",
       "5  5  25  125\n",
       "6  6  36  216\n",
       "7  7  49  343\n",
       "8  8  64  512\n",
       "9  9  81  729"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a': [[1,2,4],[1,2,4]], 'b': [[2,4,5],[1,2,4]], 'c': [[3,4,5],[1,2,4]]}\n",
    "with open('test.csv', 'w') as f:\n",
    "    for key in my_dict.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key,my_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,1,2,1,5]\n",
    "b = [4,3,3,2,1]\n",
    "\n",
    "sum(x in b for x in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv('my_csv.csv', index=False, mode='a', header=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid_x</th>\n",
       "      <th>userid_y</th>\n",
       "      <th>meetup</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>andrew-parker</td>\n",
       "      <td>10</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>bijan-sabet</td>\n",
       "      <td>6</td>\n",
       "      <td>0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>caroline-mccarthy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>mark-g</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>eric-spiegelman</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>jaime-punishill</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>jake-dwyer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>james-sims</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>jamie-dubs-wilkinson</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>fred-wilson</td>\n",
       "      <td>zachary-blank</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid_x              userid_y  meetup   percent\n",
       "14   fred-wilson         andrew-parker      10  0.035088\n",
       "25   fred-wilson           bijan-sabet       6  0.021053\n",
       "34   fred-wilson     caroline-mccarthy       5  0.017544\n",
       "139  fred-wilson                mark-g       5  0.017544\n",
       "69   fred-wilson       eric-spiegelman       4  0.014035\n",
       "..           ...                   ...     ...       ...\n",
       "88   fred-wilson       jaime-punishill       1  0.003509\n",
       "89   fred-wilson            jake-dwyer       1  0.003509\n",
       "90   fred-wilson            james-sims       1  0.003509\n",
       "92   fred-wilson  jamie-dubs-wilkinson       1  0.003509\n",
       "221  fred-wilson         zachary-blank       1  0.003509\n",
       "\n",
       "[222 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1 ,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
