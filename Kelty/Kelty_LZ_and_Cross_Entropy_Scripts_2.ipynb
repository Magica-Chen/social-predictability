{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import timeit\n",
    "import math\n",
    "import random\n",
    "from scipy.optimize import fsolve\n",
    "from mpmath import *\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import curve_fit\n",
    "#import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lempel_Ziv2(usr, lambdas=False, e=100, **kwargs):\n",
    "    \"\"\"Estimate the entropy rate of the symbols encoded in `seq`, a list of\n",
    "    strings.\n",
    "\n",
    "    Kontoyiannis, I., Algoet, P. H., Suhov, Y. M., & Wyner, A. J. (1998).\n",
    "    Nonparametric entropy estimation for stationary processes and random\n",
    "    fields, with applications to English text. IEEE Transactions on Information\n",
    "    Theory, 44(3), 1319-1327.\n",
    "\n",
    "    Bagrow, James P., Xipei Liu, and Lewis Mitchell. \"Information flow reveals\n",
    "    prediction limits in online social activity.\" Nature human behaviour 3.2\n",
    "    (2019): 122-128.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'locs' in kwargs:\n",
    "        seq = wf3[(wf3['userid']==usr) & wf3['placeid'].isin(kwargs['locs'])]['placeid'].to_list()\n",
    "        N = len(seq)\n",
    "    else:\n",
    "        seq = wf3[wf3['userid']==usr]['placeid'].to_list()\n",
    "        N = len(seq)\n",
    "    wb = 0\n",
    "\n",
    "    if N < e:\n",
    "        return [np.nan]*5\n",
    "    else:\n",
    "        L = []\n",
    "        L.append(0)\n",
    "        for i, w in enumerate(seq):\n",
    "            prevSeq = \" %s \" % \" \".join(seq[0:i])\n",
    "            seen = (\" %s \" % \" \".join(seq[i:i+1])) in prevSeq\n",
    "            c = i\n",
    "            while seen and c < N:\n",
    "                c += 1\n",
    "                seen = (\" %s \" % \" \".join(seq[i:c+1])) in prevSeq\n",
    "            \n",
    "            l = c - i\n",
    "            L.append(l)\n",
    "        wb = len([x for x in L if x != 0])\n",
    "        if lambdas:\n",
    "            return L\n",
    "        return [(1.0 * wb / sum(L)) * np.log2(N-1),sum(L),N,wb,L]\n",
    "                #,L,np.sum(L),prevSeq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy_4(ego,alters, lambdas=False, e=100, **kwargs):\n",
    "    \n",
    "    \"\"\"Estimate the entropy rate of the symbols encoded in `seq`, a list of\n",
    "    strings.\n",
    "\n",
    "    Kontoyiannis, I., Algoet, P. H., Suhov, Y. M., & Wyner, A. J. (1998).\n",
    "    Nonparametric entropy estimation for stationary processes and random\n",
    "    fields, with applications to English text. IEEE Transactions on Information\n",
    "    Theory, 44(3), 1319-1327.\n",
    "\n",
    "    Bagrow, James P., Xipei Liu, and Lewis Mitchell. \"Information flow reveals\n",
    "    prediction limits in online social activity.\" Nature human behaviour 3.2\n",
    "    (2019): 122-128.\n",
    "    \"\"\"\n",
    "#============================================================================================================================\n",
    "\n",
    "    '''\n",
    "    returns[array of cross entropies, array of weights wb (returns len(alters) + 1 elements if with ego == True),Array of Lambda_i]\n",
    "    '''\n",
    "    '''Dictionaries of Alters and their lengths are stored in an array in the order the alters were called\n",
    "    kwargs:\n",
    "        with_ego: bool, True implies we include the ego in the cummulative cross entropy\n",
    "        temporal_control: bool, True means we shuffle the time stamps of the alter locations\n",
    "    '''\n",
    "    \n",
    "    '''Lambda_i is a list of the cross-parsed match lengths of the ego based on each alter i\n",
    "    wb is a list of number of matches of substrings of A in B\n",
    "    cross_ent is the list of (cummulative) cross entropies of the alters'''\n",
    "    \n",
    "    TempCont = False\n",
    "    if 'temporal_control' in kwargs:\n",
    "        TempCont = kwargs['temporal_control']\n",
    "    '''Gets Coordinates of alters. Makes array of x-locs and y-locs\n",
    "    key is an array the size of the list of locations with all elements 'B', signifying each element as the alter's\n",
    "    N_alters is a list of the number of coordinates in the alter's string\n",
    "    Time_alters are the timestamps of the location visits\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #key denotes whether the element in the sequence is the ego's datum or alter's datum\n",
    "    \n",
    "    seq_ego = wf3[wf3['userid'] == ego]['placeid'].to_list()\n",
    "    key_ego = ['A']*len(seq_ego)\n",
    "    time_ego = wf3[wf3['userid'] == ego]['datetime'].to_list()\n",
    "    N_ego = len(seq_ego)\n",
    "    \n",
    "    if N_ego < e:\n",
    "        return float('nan')\n",
    "    \n",
    "    # Reading in the sequences of the alter(s)\n",
    "    \n",
    "    if type(alters) is list:\n",
    "        seq_alters = []\n",
    "        key_alters = []\n",
    "        time_alters = []\n",
    "        N_alters = []\n",
    "        k = 0\n",
    "        for usr in alters:\n",
    "            #print(usr)\n",
    "            seq_alters.append(wf3[wf3['userid'] == usr]['placeid'].to_list())\n",
    "            key_alters.append(['B']*len(seq_alters[k]))\n",
    "            time_alters.append(wf3[wf3['userid'] == usr]['datetime'].to_list())\n",
    "            N_alters.append(len(seq_alters[k]))\n",
    "            if TempCont:\n",
    "                '''If we want a temporally controlled entropy, we shuffle the times and sort the \n",
    "                locations with respect to the shuffled time list'''\n",
    "                random.shuffle(time_alters[k])\n",
    "                seq_alters[k] = [x for _, x in sorted(zip(time_alters[k],seq_alters[k]))]\n",
    "                seq_alters[k] = [x for _, x in sorted(zip(time_alters[k],seq_alters[k]))]\n",
    "            k+=1\n",
    "    else:\n",
    "        k=0\n",
    "        seq_alters = [wf3[wf3['userid'] == alters]['placeid'].to_list()]\n",
    "        key_alters = [['B']*len(seq_alters[k])]\n",
    "        time_alters = [wf3[wf3['userid'] == alters]['datetime'].to_list()]\n",
    "        N_alters = [len(seq_alters[0])]\n",
    "        if TempCont:\n",
    "            random.shuffle(time_alters)\n",
    "            seq_alters = [x for _, x in sorted(zip(time_alters,seq_alters))]\n",
    "    \n",
    "    \n",
    "\n",
    "#============================================================================================================\n",
    "#============================================================================================================\n",
    " \n",
    "\n",
    "    L_i = []\n",
    "    Lambda_max = []\n",
    "    wb = []\n",
    "    cumcross_ent = []\n",
    "    cross_ents = []\n",
    "    mut_unique =[]\n",
    "    num_mut_unique = []\n",
    "    cum_mut_unique = []\n",
    "    cumnum_mut_unique = []\n",
    "    N_Ego_Seen = []\n",
    "    \n",
    "    #L_i = {L_i}\n",
    "    #Lambda_max = max({Lambda_i} for all i for all  alters)\n",
    "    #wb = list of weights of pairs\n",
    "    #cross ents = list of cross entropies\n",
    "    #mut_unqiue = list of lists of mutual locations shared between an ego and alter\n",
    "    #num_mut_unique = {len(mut_unique[i])} for all i\n",
    "    #cum_mut_unique = list of cummulative shared mutual locations betwen the ego and all alters\n",
    "    #cumnum_mut_unique = length of ^\n",
    "    #N_Ego_Seen = the number of elements seen by the ego that have been previously seen by all alters, i.e. len(Lambda_max)\n",
    "    #where Lambda_max_i != 0\n",
    "\n",
    "#============================================================================================================\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    k = -1\n",
    "    ego_index = 0\n",
    "    if 'with_ego' in kwargs:\n",
    "        with_ego = kwargs['with_ego']\n",
    "        if kwargs['with_ego']:\n",
    "            dummy = Lempel_Ziv(ego)\n",
    "            N_alters.insert(0,dummy[2])\n",
    "            wb.append(dummy[2])\n",
    "            L_i.append(dummy[4])\n",
    "            ego_index = 1\n",
    "    else:\n",
    "        with_ego = False \n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    " \n",
    "    for ALTER in seq_alters:\n",
    "        i = 0\n",
    "        i_ego = 0\n",
    "        i_alter = 0\n",
    "        k+=1\n",
    "        dict_ego = []\n",
    "        dict_alter = []\n",
    "        mut_unique.append([])\n",
    "        wb.append(0)\n",
    "        num_mut_unique.append(0)\n",
    "        \n",
    "#Sort sequences with respect to time, preserving the order of the individual ego/alter sequences through the key\n",
    "        seq = seq_alters[k] + seq_ego\n",
    "        key = key_alters[k] + key_ego\n",
    "        times = time_alters[k] + time_ego\n",
    "        key = [x for _, x in sorted(zip(times,key))]\n",
    "        seq = [x for _, x in sorted(zip(times,seq))]\n",
    "        times = sorted(times)\n",
    "        N_alters[k+ego_index] = N_alters[k+ego_index] - key[::-1].index('A')\n",
    "        seq = seq[:(len(key)-key[::-1].index('A'))]\n",
    "        key = key[:(len(key)-key[::-1].index('A'))]\n",
    "        \n",
    "        #If after intializing the sequences the alter's string length is not long enough, go to the next alter\n",
    "        if N_alters[k + ego_index] < 200:\n",
    "            N_alters[k + ego_index] = 0\n",
    "            wb[-1] = 0\n",
    "            L_i.append([0]*N_ego)\n",
    "            cross_ents.append(float('nan'))\n",
    "        else:\n",
    "            i_ego = 0\n",
    "            i_alter = 0\n",
    "            prevSeq = 0\n",
    "            L_i.append([])\n",
    "            for i, w in enumerate(seq):\n",
    "                if key[i] == 'B':\n",
    "                    i_alter += 1\n",
    "                else:\n",
    "                    prevSeq = \" %s \" % \" \".join(seq_alters[k][0:i_alter])\n",
    "                    seen = (\" %s \" % \" \".join(seq_ego[i_ego:i_ego+1])) in prevSeq\n",
    "                    c = i_ego\n",
    "                    while seen and c < N_ego:   \n",
    "                        c += 1\n",
    "                        seen = (\" %s \" % \" \".join(seq_ego[i_ego:c+1])) in prevSeq\n",
    "                        if seq_ego[c - 1] not in mut_unique[-1]:\n",
    "                            num_mut_unique[-1] += 1\n",
    "                            mut_unique[-1].append(seq_ego[c - 1])\n",
    "                \n",
    "                    l = c - i_ego\n",
    "                    i_ego += 1\n",
    "                    L_i[-1].append(l)\n",
    "                \n",
    "            wb[-1] = len([x for x in L_i[-1] if x != 0])\n",
    "            \n",
    "            \n",
    "            if wb[-1] < e:\n",
    "                N_alters[k + ego_index] = 0\n",
    "                L_i[-1] = [0]*len(L_i[-1])\n",
    "                cross_ents.append(float('nan'))\n",
    "            else:\n",
    "                cross_ents.append(wb[-1]*np.log2(N_alters[k+ego_index])/sum(L_i[-1]))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "                \n",
    "                \n",
    "        if with_ego == True:\n",
    "            N_ego = len([x for x in L_i[-1] if x != 0])\n",
    "            N_AB_one = (wb[0]*N_ego + wb[-1]*N_alters[k + ego_index])/(wb[0]+wb[-1])\n",
    "            Lambda_max_one = np.sum(np.nanmax([L_i[0],L_i[-1]],axis=0))\n",
    "            if (N_alters[k + ego_index] < e) or (wb[-1] < e):\n",
    "                cross_ents.append(float('nan'))\n",
    "            else:\n",
    "                cross_ents.append(N_ego*np.log2(N_AB_one)/Lambda_max_one)\n",
    "        #Finding the Cumulative Unique Locations\n",
    "        if cum_mut_unique == []:\n",
    "            cum_mut_unique.append(mut_unique[-1])\n",
    "            cumnum_mut_unique.append(num_mut_unique[-1])\n",
    "        else:\n",
    "            cum_mut_unique.append(list(set(mut_unique[-1] + cum_mut_unique[-1])))\n",
    "            cumnum_mut_unique.append(len([x for x in mut_unique[-1] if x not in cum_mut_unique[-2]]))\n",
    "        \n",
    "        #Calculating CCE\n",
    "        N_AB = np.sum(np.multiply(wb,N_alters[:len(wb)]))/np.sum(wb)\n",
    "        Lambda_max = np.nanmax(L_i,axis=0)\n",
    "        N_Ego_Seen.append(len([x for x in Lambda_max if x != 0]))\n",
    "        cumcross_ent.append(N_Ego_Seen[-1]*np.log2(N_AB)/np.sum(Lambda_max))\n",
    "        \n",
    "        \n",
    "        if mut_unique[-1] == []:\n",
    "            mut_unique[-1] = [float('nan')]\n",
    "            if cum_mut_unique[-1] == []:\n",
    "                cum_mut_unique[-1] = [float('nan')]\n",
    "\n",
    "                \n",
    "#============================================================================================================\n",
    "#============================================================================================================\n",
    " \n",
    "    if lambdas:\n",
    "        return L\n",
    "    return [cumcross_ent,cross_ents,wb[ego_index:],N_alters[ego_index:],num_mut_unique,np.cumsum(cumnum_mut_unique),mut_unique,cum_mut_unique,N_Ego_Seen,list(Lambda_max)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fano Inequality'''\n",
    "def Fano(Pi_max, N, S):\n",
    "    return np.log2(N-1)-S+Pi_max*np.log2((1/Pi_max - 1)*(1/(N-1))) - np.log2(1-Pi_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
